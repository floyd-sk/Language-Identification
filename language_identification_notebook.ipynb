{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcad82e7",
   "metadata": {},
   "source": [
    "# **South African Language Identification Hackathon**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fc096",
   "metadata": {},
   "source": [
    "As a multicultural society, South Africa is characterised by its rich linguistic diversity with 11 official languages. The aim of this machine learning model is to characterize pieces of text to the natural language in which it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec198d",
   "metadata": {},
   "source": [
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80ae66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nobuhle.skakane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nobuhle.skakane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Packages for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Packages for visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "\n",
    "# Packages for preprocessing\n",
    "import textblob\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import spacy.cli\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Packages for training models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n",
    "# Model Evaluation Packages\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Style\n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a84b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nobuhle.skakane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nobuhle.skakane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nobuhle.skakane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "spacy.load('en_core_web_sm')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318d32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefbd188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nobuhle.skakane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461bffd",
   "metadata": {},
   "source": [
    "# 2.Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21f5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_set.csv')\n",
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c0e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()\n",
    "sample_submission_copy = df_sample_submission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b493be19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb5225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2745eaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce282b7",
   "metadata": {},
   "source": [
    "# 3. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "640f1986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000bc88b",
   "metadata": {},
   "source": [
    "# 4.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c4b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Knowing that we are dealing with text data, we decided to first clean the data by making all tweets lower-case, removing punctuation marks and removing white spaces before doing anything else. Also, replacing all links with the word 'LINK' and all user handles with 'USER_REF'\n",
    "\"\"\"\n",
    "def clean_text(df_copy):\n",
    "    i = 0\n",
    "    for text in df_copy['text']:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http\\S+', 'LINK', text)\n",
    "        text = re.sub(r'@\\S+', 'USER_REF', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = text.lstrip()\n",
    "        text = text.rstrip()\n",
    "        text = text.replace('  ', ' ')\n",
    "        df_copy.loc[i, 'text'] = text\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8f5b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df_copy):\n",
    "    my_stop_words = stopwords.words('english')\n",
    "    my_stop_words.append('LINK')\n",
    "    my_stop_words.append('USER_REF')\n",
    "\n",
    "    df_copy_index = 0\n",
    "\n",
    "    for text in df_copy['text']:\n",
    "        text = word_tokenize(text)\n",
    "        text = [word for word in text if not word in my_stop_words]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "        df_copy.loc[df_copy_index, 'text'] = text\n",
    "        df_copy_index += 1\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f71785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_text(df_copy):\n",
    "    df_copy_index = 0\n",
    "\n",
    "    for text in df_copy['text']:\n",
    "        text = nlp(text)\n",
    "      \n",
    "        for token in text:\n",
    "            df_copy.loc[df_copy_index, 'text'] = df_copy.loc[df_copy_index, 'text'].replace(str(token.text), str(token.lemma_))\n",
    "\n",
    "            df_copy_index += 1\n",
    "\n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f80dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>province kwazulunatal department transport inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>netefatša gore ba file dilo ka moka tše le dum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na ntse sa utlwe hore thabang ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date submission completed tenders augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha mang le ona lokela ho etsa ditlaleho t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "0         xho  umgaqosiseko wenza amalungiselelo kumaziko axh...\n",
       "1         xho  idha iya kuba nobulumko bokubeka umsebenzi nap...\n",
       "2         eng  province kwazulunatal department transport inv...\n",
       "3         nso  netefatša gore ba file dilo ka moka tše le dum...\n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "...       ...                                                ...\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996     sot  modise mosadi na ntse sa utlwe hore thabang ra...\n",
       "32997     eng  closing date submission completed tenders augu...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha mang le ona lokela ho etsa ditlaleho t...\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(df_train_copy)\n",
    "remove_stopwords(df_train_copy)\n",
    "lem_text(df_train_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab5fac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mmasepala fa maemo kgethegileng letlelela kgat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>mark ballot private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>ge ka kgetha ka bowena go se šomiše mofani ka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>e ka kopo etsa kgetho ya hao ka hloko hobane h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>tb ke bokudi ba pmb mme morero tla lefella tlh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>vakatjhela iwebhusayidi yethu kuwww</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         1  mmasepala fa maemo kgethegileng letlelela kgat...\n",
       "1         2  uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2         3          tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3         4  kube inja nelikati betingevakala kutsi titsini...\n",
       "4         5                       winste op buitelandse valuta\n",
       "...     ...                                                ...\n",
       "5677   5678                                mark ballot private\n",
       "5678   5679  ge ka kgetha ka bowena go se šomiše mofani ka ...\n",
       "5679   5680  e ka kopo etsa kgetho ya hao ka hloko hobane h...\n",
       "5680   5681  tb ke bokudi ba pmb mme morero tla lefella tlh...\n",
       "5681   5682                vakatjhela iwebhusayidi yethu kuwww\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(df_test_copy)\n",
    "remove_stopwords(df_test_copy)\n",
    "lem_text(df_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daddc5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-76558fcd7a8d>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train_copy[\"text\"] = df_train_copy[\"text\"].str.replace(\".txt\", \" text file\")\n",
      "<ipython-input-16-76558fcd7a8d>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test_copy[\"text\"] = df_test_copy[\"text\"].str.replace(\".txt\", \" text file\")\n"
     ]
    }
   ],
   "source": [
    "# Replace '.txt' with 'text file'\n",
    "df_train_copy[\"text\"] = df_train_copy[\"text\"].str.replace(\".txt\", \" text file\")\n",
    "df_test_copy[\"text\"] = df_test_copy[\"text\"].str.replace(\".txt\", \" text file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61a5e9",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd8bc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_copy['text']\n",
    "y = df_train_copy['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974cd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ddf896",
   "metadata": {},
   "source": [
    "# 6. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c462daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the different Classification models we will train our data on\n",
    "# Creating a list of names so we can print metrics for the entire list at once\n",
    "names = ['Logistic Regression'\n",
    "         , 'Nearest Neighbors'\n",
    "         , 'Multinomial Naive Bayes'\n",
    "         #, 'Linear SVC'\n",
    "         , 'RBF SVC'\n",
    "         , 'Linear SVM'\n",
    "         , 'Decision Tree'\n",
    "         #, 'Random Forest'\n",
    "         #, 'AdaBoost'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd85d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the different Classification models we will train our data on\n",
    "# Creating a list of names so we can print metrics for the entire list at once\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=42, multi_class='ovr', n_jobs=1, C=1e5, max_iter=4000)\n",
    "    , KNeighborsClassifier(n_neighbors=5)\n",
    "    , MultinomialNB()\n",
    "    #, SVC(kernel=\"linear\", C=0.025)\n",
    "    , SVC(gamma=2, C=1)\n",
    "    , LinearSVC(random_state=42)\n",
    "    , DecisionTreeClassifier(max_depth=5)\n",
    "    #, RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "    #, AdaBoostClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37b4281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_building(classifiers, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    This function takes in a list of classifiers\n",
    "    and both the train and validation sets\n",
    "    and return a summary of F1-score and\n",
    "    processing time as a dataframe\n",
    "\n",
    "    Input:\n",
    "    classifiers: a list of classifiers to train\n",
    "                 datatype: list\n",
    "    X_train: independent variable for training\n",
    "             datatype: series\n",
    "    y_train: dependent variable for training\n",
    "             datatype: series\n",
    "    X_val: independent variable for validation\n",
    "           datatype: series\n",
    "    y_val: dependent variable for validation\n",
    "           datatype: series\n",
    "\n",
    "    Output:\n",
    "    model_summary: F1 Score for all the classifiers\n",
    "                   datatype: dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    models_summary = {}\n",
    "\n",
    "    # Pipeline to balance the classses and then to build the model\n",
    "    for clf in classifiers:\n",
    "        clf_text = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                       max_df=0.9,\n",
    "                                                       ngram_range=(1, 2))),\n",
    "                             ('clf', clf)])\n",
    "\n",
    "        # Logging the Execution Time for each model\n",
    "        start_time = time.time()\n",
    "        clf_text.fit(X_train, y_train)\n",
    "        predictions = clf_text.predict(X_val)\n",
    "        run_time = time.time()-start_time\n",
    "\n",
    "        # Output for each model\n",
    "        models_summary[clf.__class__.__name__] = {\n",
    "            'F1-Macro': metrics.f1_score(y_val,\n",
    "                                         predictions,\n",
    "                                         average='macro'),\n",
    "            'F1-Accuracy': metrics.f1_score(y_val, predictions,\n",
    "                                            average='micro'),\n",
    "            'F1-Weighted': metrics.f1_score(y_val,\n",
    "                                            predictions,\n",
    "                                            average='weighted'),\n",
    "            'Execution Time': run_time}\n",
    "\n",
    "    return pd.DataFrame.from_dict(models_summary, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d1ede5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.999092</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>10.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>201.736941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.995750</td>\n",
       "      <td>0.995758</td>\n",
       "      <td>0.995756</td>\n",
       "      <td>15.511536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.991615</td>\n",
       "      <td>0.991515</td>\n",
       "      <td>0.991550</td>\n",
       "      <td>1389.323175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.967434</td>\n",
       "      <td>0.967576</td>\n",
       "      <td>0.967332</td>\n",
       "      <td>15.656766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.511836</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.505642</td>\n",
       "      <td>14.652031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1-Macro  F1-Accuracy  F1-Weighted  Execution Time\n",
       "MultinomialNB           0.999092     0.999091     0.999091       10.002316\n",
       "LogisticRegression      0.996055     0.996061     0.996060      201.736941\n",
       "LinearSVC               0.995750     0.995758     0.995756       15.511536\n",
       "SVC                     0.991615     0.991515     0.991550     1389.323175\n",
       "KNeighborsClassifier    0.967434     0.967576     0.967332       15.656766\n",
       "DecisionTreeClassifier  0.511836     0.546364     0.505642       14.652031"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers_df = models_building(classifiers, X_train, y_train, X_val, y_val)\n",
    "ordered_df = classifiers_df.sort_values('F1-Macro', ascending=False)\n",
    "ordered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813d2e6",
   "metadata": {},
   "source": [
    "As can be seen above, Multinomial Naive Bayes is the best performing model and we perform further hyperparameter tuning below;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5a32a",
   "metadata": {},
   "source": [
    "# 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d65ab7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refining the train-test split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c3c9bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00        28\n",
      "         eng       1.00      1.00      1.00        36\n",
      "         nbl       1.00      1.00      1.00        19\n",
      "         nso       1.00      1.00      1.00        31\n",
      "         sot       1.00      1.00      1.00        32\n",
      "         ssw       1.00      1.00      1.00        28\n",
      "         tsn       1.00      1.00      1.00        29\n",
      "         tso       1.00      1.00      1.00        21\n",
      "         ven       1.00      1.00      1.00        31\n",
      "         xho       1.00      1.00      1.00        31\n",
      "         zul       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00       330\n",
      "   macro avg       1.00      1.00      1.00       330\n",
      "weighted avg       1.00      1.00      1.00       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a pipeline for the gridsearch\n",
    "param_grid = {'alpha': [0.1, 1, 5, 10]}  # setting parameter grid\n",
    "\n",
    "tuned_mnb = Pipeline([('tfidf', TfidfVectorizer(min_df=2,\n",
    "                                                max_df=0.9,\n",
    "                                                ngram_range=(1, 2))),\n",
    "                      ('mnb', GridSearchCV(MultinomialNB(),\n",
    "                                           param_grid=param_grid,\n",
    "                                           cv=5,\n",
    "                                           n_jobs=-1,\n",
    "                                           scoring='f1_weighted'))\n",
    "                      ])\n",
    "\n",
    "tuned_mnb.fit(X_train, y_train)  # Fitting the model\n",
    "\n",
    "y_pred_mnb = tuned_mnb.predict(X_val)  # predicting the fit on validation set\n",
    "\n",
    "print(classification_report(y_val, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc32563",
   "metadata": {},
   "source": [
    "# 8. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2a72744",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(df_test_copy['index'])\n",
    "submission['lang_id'] = tuned_mnb.predict(df_test_copy['text'])\n",
    "submission.to_csv('submission_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba47f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
